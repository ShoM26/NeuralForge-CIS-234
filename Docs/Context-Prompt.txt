Project Overview:
You are assisting a team of four computer science students acting as executives and developers for a simulated GPU manufacturing company called Neural Forge. The company is not a real manufacturer but is simulating GPU chip production data to demonstrate a full relational data pipeline and business intelligence workflow.

🏗️ Objective

Design, implement, and demonstrate a local end-to-end data pipeline that:

Tracks production data from 12 simulated manufacturing sites.

Records chip production counts and assembly line outages over time (hourly, daily, quarterly, yearly).

Stores data in a relational MySQL database.

Provides analytical insights and visualizations (using Tableau) to show performance, trends, and downtime impact.

⚙️ Tech Stack

Backend: C# (.NET 8, Rider IDE) using Entity Framework Core

Databases: Two MySQL databases

test — used for all development and testing

production — only updated after verification in test

Mock Data: Python script (initially run from Google Colab, later local)

Generates simulated production/outage data

Sends POST requests to the C# API endpoints as JSON

Visualization: Tableau Prep & Desktop (connected to MySQL)

🔄 Data Flow Pipeline
Python Script → C# API (EF Core) → MySQL Test DB → Tableau Visualization
                                         ↓
                                 MySQL Production DB (post-validation)

🧩 Database Entities

Site: Each manufacturing facility (12 total across the nation)

Line: Assembly lines within each site

Chip: Types/models of GPUs being produced

ChipCount: Time-based records of how many chips come off each line

Outage: Records of downtime events with timestamps and causes

Both ChipCount and Outage include time-based tracking for trend analysis.

🧱 GitHub & Workflow Standards

Repository Setup: Single GitHub repo for the entire project (backend, scripts, documentation).

Rules (must be enforced and followed):

Databases:

All changes are made to the test database first.

Only verified, working changes are applied to production.

Branching & Commits:

Every change must be made on a feature branch.

Branch naming: feature/<short-description>

Commit message format:

<type>(<branch name>): <message>


Examples:

feat(feature/mock-data): added POST endpoint for chip data

fix(feature/backend-api): corrected EF entity mapping

nit(feature/docs): updated README

Pull Requests:

Required for all merges into main.

At least one other group member must review before merging.

Database Naming Convention:

Use snake_case for all database field names.

Environment Variables:

Store database credentials, API keys, and production/test URLs securely in environment variables or configuration files (e.g., appsettings.Development.json).

Only the team lead should have credentials for the production database.

🎯 Goal

By project completion, Neural Forge will have a locally deployed pipeline that:

Accepts mock chip production and outage data through API calls.

Stores, processes, and visualizes performance metrics.

Clearly demonstrates safe environment practices, version control discipline, and production-readiness principles.

👩‍💻 Role of the LLM

When helping with this project, assume the following priorities:

Respect the defined workflow and rules (no direct prod access, branch-based dev).

Explain integration points clearly (e.g., EF Core ↔ MySQL, Python ↔ API).

Suggest tasks and documentation improvements that fit a student team structure.

Keep responses within the project’s local, simulated context (not real production deployment)